{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28949d92-1eb4-4247-9bc6-1d7bc6f13dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_name</th>\n",
       "      <th>weight_brutto</th>\n",
       "      <th>weight_netto</th>\n",
       "      <th>fill_level</th>\n",
       "      <th>max_weight_netto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0000000000000</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>457</td>\n",
       "      <td>405</td>\n",
       "      <td>1,0000000000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>445</td>\n",
       "      <td>393</td>\n",
       "      <td>0,9703703703704</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>435</td>\n",
       "      <td>383</td>\n",
       "      <td>0,9456790123457</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>422</td>\n",
       "      <td>370</td>\n",
       "      <td>0,9135802469136</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folder_name  weight_brutto  weight_netto       fill_level  max_weight_netto\n",
       "0            1             52             0  0,0000000000000             405.0\n",
       "1            2            457           405  1,0000000000000               NaN\n",
       "2            3            445           393  0,9703703703704               NaN\n",
       "3            4            435           383  0,9456790123457               NaN\n",
       "4            5            422           370  0,9135802469136               NaN"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# Disable GPU usage (GPUs add no value for the small example and we do not need to fight for ressources this way) \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "df = pd.read_csv('linearRegressionData/KI/ki-data.csv', sep=';') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79eb00d9-0671-4e7c-839d-61e40c3a5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y = pd.DataFrame()\n",
    "\n",
    "#Y['fill_level'] = df.fill_level\n",
    "\n",
    "#Y.head()\n",
    "\n",
    "Y = []\n",
    "for fillLevel in df.fill_level:\n",
    "    Y.append(float(fillLevel.replace(\",\", \".\" )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95effa3-7d94-470a-903b-46eb335b8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # image data\n",
    "IMG_SIZE = 32\n",
    "def preprocess_image(path):\n",
    "    image = np.array(Image.open(path))\n",
    "    image = cv2.resize(image,(IMG_SIZE, IMG_SIZE))\n",
    "    return image / 255.0\n",
    "    \n",
    "for folder in df.folder_name:\n",
    "    path = \"linearRegressionData/KI/\" + str(folder)\n",
    "    files = os.listdir( path )\n",
    "    for file in files:\n",
    "        image = preprocess_image(os.path.join(path, file))\n",
    "        X.append(image)\n",
    "        pass\n",
    "        \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c9f589-c21c-4aa4-9b19-0a6d4fc92ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"Xreg.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Yreg.pickle\", \"wb\")\n",
    "pickle.dump(Y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96dc3f6-7e27-4098-9431-a2a4a30a2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_in = open(\"Xreg.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in) # load feature set\n",
    "pickle_in.close()\n",
    "\n",
    "pickle_in = open(\"Yreg.pickle\", \"rb\")\n",
    "Y = pickle.load(pickle_in) # load labels\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42dff240-d4c4-4230-bd72-892a26ce61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Y = np.array(Y)\n",
    "Y = Y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9796bd86-3f29-4cfa-b303-0d756ccc0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle input data\n",
    "\n",
    "Z = list(zip(X, Y))\n",
    "\n",
    "import random\n",
    "\n",
    "random.shuffle(Z)\n",
    "X_shuffle = []\n",
    "Y_shuffle = []\n",
    "for x, y in Z:\n",
    "    X_shuffle.append(x)\n",
    "    Y_shuffle.append(y)\n",
    "    \n",
    "X_shuffle = np.array(X_shuffle)\n",
    "Y_shuffle = np.array(Y_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16cf51d-cb1a-46bd-a06f-ddc905616376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_shuffle, Y_shuffle, test_size=0.20) # shuffled data\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "110da1ff-614a-4440-acce-15647aacce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(8, input_shape=(32, 32, 3), activation = 'relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb9b2ace-0c71-47ae-a762-3ac93bf1522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(64, input_shape=(32, 32, 3), activation = 'relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(54, activation = 'relu'))\n",
    "model.add(Dropout(0.18))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "884da8ce-4234-491f-add3-bbc633711985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(64, input_shape=(32, 32, 3), activation = 'relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dropout(0.18))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "624fd44a-c990-4a78-8627-16ced385119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(32, input_shape=(32, 32, 3), activation = 'relu'))\n",
    "model.add(Dropout(0.18))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1cb9ec60-22d4-428b-8316-78dfc0bf9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(512, input_shape=(32, 32, 3), activation = 'relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "259e9dd4-11d7-4392-9dd9-339b775fc9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7b7fcc8-9036-4fc7-a63a-acd449b12ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 12ms/step - loss: 0.0868 - accuracy: 0.0122\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0379 - accuracy: 0.0183\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0241 - accuracy: 0.0244\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0241 - accuracy: 0.0244\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0225 - accuracy: 0.0244\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.0244\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.0244\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.0244\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0165 - accuracy: 0.0244\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.0244\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0175 - accuracy: 0.0244\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.0244\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.0244\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.0244\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 0.0244\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.0244\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.0244\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.0244\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.0244\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.0244\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0227 - accuracy: 0.0183\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.0244\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0234 - accuracy: 0.0244\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.0244\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.0244\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.0244\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.0244\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0230 - accuracy: 0.0244\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.0244\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.0244\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.0244\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.0244\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 0.0244\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.0244\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.0244\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.0244\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 0.0244\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.0244\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.0244\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.0244\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.0244\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 0.0244\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0144 - accuracy: 0.0244\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.0244\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.0244\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.0244\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0133 - accuracy: 0.0244\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0168 - accuracy: 0.0244\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.0244\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.0244\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.0244\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0161 - accuracy: 0.0244\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0161 - accuracy: 0.0244\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 0.0244\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.0244\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.0244\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 0.0244\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.0244\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0172 - accuracy: 0.0244\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0154 - accuracy: 0.0244\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.0244\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.0244\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.0244\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.0244\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0154 - accuracy: 0.0244\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0126 - accuracy: 0.0244\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.0244\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.0244\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0134 - accuracy: 0.0244\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 0.0244\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.0244\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 0.0244\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0141 - accuracy: 0.0244\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.0244\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.0244\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 0.0244\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.0244\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0108 - accuracy: 0.0244\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.0244\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.0244\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.0244\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.0244\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0167 - accuracy: 0.0244\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.0244\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.0244\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 0.0244\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.0244\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 0.0244\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.0244\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.0244\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.0244\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.0244\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0144 - accuracy: 0.0244\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.0244\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 0.0244\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.0244\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.0183\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.0244\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.0244\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.0244\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 0.0244\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.0244\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.0244\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.0244\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.0244\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 0.0244\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.0244\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0115 - accuracy: 0.0244\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0141 - accuracy: 0.0244\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.0244\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.0183\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.0244\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0141 - accuracy: 0.0244\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.0244\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.0244\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.0244\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.0244\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.0244\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.0244\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.0244\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0126 - accuracy: 0.0244\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0098 - accuracy: 0.0244\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0147 - accuracy: 0.0244\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.0244\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.0183\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.0244\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.0244\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 0.0244\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 0.0244\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.0183\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.0244\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.0244\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 0.0244\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.0244\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.0244\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.0244\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0133 - accuracy: 0.0244\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0108 - accuracy: 0.0244\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.0244\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 0.0244\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.0244\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 0.0244\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 0.0244\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 0.0244\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0115 - accuracy: 0.0244\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.0244\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.0244\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0130 - accuracy: 0.0244\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.0244\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 0.0244\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0141 - accuracy: 0.0244\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.0244\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0148 - accuracy: 0.0244\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0130 - accuracy: 0.0244\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0154 - accuracy: 0.0244\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.0244\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 0.0244\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 0.0244\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0109 - accuracy: 0.0244\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.0244\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.0244\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 0.0244\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0165 - accuracy: 0.0244\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0171 - accuracy: 0.0244\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.0244\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0143 - accuracy: 0.0244\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.0244\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 0.0244\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0130 - accuracy: 0.0244\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0110 - accuracy: 0.0244\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 0.0244\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 0.0244\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.0244\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0141 - accuracy: 0.0244\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.0244\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0159 - accuracy: 0.0244\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 0.0244\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 0.0244\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.0244\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.0244\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.0244\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.0244\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.0244\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.0244\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0108 - accuracy: 0.0244\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 0.0244\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.0244\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.0244\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.0244\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0134 - accuracy: 0.0244\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0134 - accuracy: 0.0244\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.0244\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.0244\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 0.0244\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.0244\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0113 - accuracy: 0.0244\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 0.0244\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 0.0244\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.0244\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 0.0244\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Disable GPU usage (GPUs add no value for the small example and we do not need to fight for ressources this way) \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "history = model.fit(X_train, Y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d8e72b8-51a0-49fc-9f61-c34c0b674302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f58d8734460>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plot the loss and validation loss of the dataset\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7e68f-3c45-42bb-811b-dfcb3b8db8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
